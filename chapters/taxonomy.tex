\chapter{Desugaring in the Wild}\label{chap:taxonomy}

There are a bewildering variety of desugaring systems.  In this
chapter, we categorize a representative set of them into a taxonomy.

We stretch this taxonomy to include some systems that aren't quite
desugaring systems, but that are closely associated with
them. Notably, we discuss staged metaprogramming systems, which (i)
operate on code at run-time, rather than compile-time, and (ii) have
to explicitly, rather than implicitly, desugar code.

\section{A Sugar Taxonomy}

There are many dimensions by which desugaring mechanisms vary:
\begin{description}
  \item[Representation] Desugaring is a syntax-to-syntax transformation, but
    how is that syntax represented? There is a big difference between
    transformations on the \emph{text} of the program vs.\ its
    \emph{concrete surface syntax} vs.\ its \emph{abstract surface
      syntax}.
  \item[Authorship] Are sugars defined by developers of the language (and thus
    relatively fixed), or by users of the language (and thus flexible)?
  \item[Metalanguage] What is the metalanguage? That is, in what language are sugars
    written? Is it the same language the programs are written in, thus
    allowing sugars and code to be interspersed, or a different
    language?
  \item[Desugaring Order] In what order are constructs desugared? Most
    importantly, are nested sugars desugared from the \emph{innermost
      to outermost} (\Sc{io}), or from \emph{outermost to innermost}
    (\Sc{oi})?
  \item[Time of Expansion] \emph{When} does desugaring occur? Is it at compilation time,
    or at run-time (as in staged metaprogramming
    systems)?\marginpar{%
    As previously noted, if the ``phase'' at which desugaring happens
    is run-time, then the system isn't really a desugaring system,
    though it may be similar enough to warrant our classification of it.}
\end{description}
We will consider four dimensions related to the \emph{expressiveness}
of desugaring systems:
\begin{description}
  \item[Parameters] Can a sugar take an
    arbitrary expression as a parameter, or only a primitive value?
  \item[Result] Do sugars exclusively produce expressions, or can they
    produce any kind of syntax?
  \item[Deconstruction] If it can take an expression, can it
    deconstruct it, or only use it parametrically?
  \item[Sugar-defining Sugars] Can sugars define other sugars?
\end{description}
We will also consider four dimensions related to \emph{safety}:
\begin{description}
  \item[Syntactic Safety] Can desugaring produce syntactically invalid
    code?
  \item[Hygiene] Can a sugar accidentally capture a variable?
  \item[Scope Safety] Can a sugar produce an unbound variable?
  \item[Type Safety] Can a sugar produce code that contains a type
    error?
\end{description}

We next discuss each of these dimensions in detail. After that,
\cref{table:taxonomy-table} assesses a number of desugaring systems
along these dimensions, and \cref{sec:taxonomy-systems} discusses
these desugaring systems.

\subsection{Representation}

There are many ways to represent a program. The most prevalent are as
\emph{text} and as a \emph{tree}. Programs are most commonly
\emph{saved as} and \emph{edited as} text (notable exceptions include
languages or editors that are visual, block based, or projectional),
and they are most commonly
\emph{internally represented as} trees (notable exceptions include
assembly, whose code is linear, and Forth, which does not have a
parsing phase).

Desugaring systems may be based on either representation.
\emph{However, text is a terrible representation for desugaring rules.}
The semantics of a language is almost always defined in terms of its
(abstract syntax) tree representation. Thus, insofar as a programmer
is forced to think of their program as text rather
than as a tree, they are being distracted from its semantics. There
are well-known examples of bugs that arise in text-based desugaring
rules unless they are written in a very defensive style: we discuss
these in \ref{sec:taxonomy-cpre}.

There are variations among tree representations as well: desugaring
rules may work over the concrete syntax of the language, or over its
abstract syntax. The \emph{concrete} syntax of a language is its
syntax as seen by the programmer, e.g. \Code{f(1)} for a function
application. The \emph{abstract} syntax is the internal representation
of that syntax, which for this example might (e.g.) be
\Code{(apply (id f) 1)}. Concrete syntax might seem similar to a
text-based representation, but there is an important distinction:
\Code{f(1} in a textual representation is part of a term, but
there is no such thing as \Code{f(1} in the concrete syntax: it is
ill-formed.

Overall, this is a \emph{very loose} categorization of
representations: we are placing a wide variety of possible
representations into a few large buckets.


\subsection{Authorship: Language-defined or User-defined}

Sugars may either be specified and implemented as part of the
language, or they may be defined by users. For example, Haskell list
comprehensions are defined by the Haskell spec~\cite{haskell-language} and implemented
in the compiler(s); thus they are language-defined. Template Haskell
sugars~\cite{haskell-templates}, on the other hand, can be defined (and used) in any
Haskell program; thus they are user-defined.

Language-defined sugars are a convenient method of simplifying
language design, and they are largely invisible: ideally,
users of the language should not be able to tell which syntactic
constructs were implemented as sugar and which were built in.
In contrast, user-defined sugars are much more visible. They give
users the power to extend the language. As a consequence, when
this extended language is shared, other users must contend with it,
which may be a gift or a burden, depending on its quality.

%% [TODO: Consider moving the rest of this prose into a different section.]

%% When sugars are user-defined, it raises difficulties with tools such
%% as editors that need to support the new syntax. For example, if sugars
%% are language-defined then an editor can just support the full
%% language. If they are user-defined, however, how can an editor provide
%% correct indentation, syntax highlighting, etc.? % TODO: rewrite this paragraph

%% Different languages work around this problem in different ways.

%% Lisps partly avoid this problem by having two ``layers'' of syntax.
%% The lower layer is simply s-expressions, and ensures that parentheses
%% are well-balanced (and that there are no tokenization errors).
%% The higher layer checks that the s-expression makes syntactic sense.
%% For example, \Code{(define x 1} is invalid at both layers,
%% \Code{(define ((x)) 1)} is valid at the first layer but not at the
%% second, and \Code{(define x 1)} is valid at both layers.
%% This can be called \emph{bicameral syntax}[CITE: plai], by analogy to legislative
%% houses that are split into a lower and upper level.

%% This separation of concerns makes it easy for editors to support the
%% \emph{first} layer of syntax, which cannot be modified by syntactic
%% sugar, while ignoring the second, which can. Doing so only
%% \emph{partly} avoids the problem. For example, the DrRacket editor for
%% Racket [CITE] allows indentation schemes to be set on a per-macro
%% basis (because different syntactic forms, while purely parenthetical,
%% still have varying nesting patterns that should be indented
%% differently), and it displays arrows showing where variables are bound
%% by being macro-aware and expanding the program (see [REF]).

%% [FILL: SugarJ, other examples]
%% [FILL: Spoofax, language workbenches: tie editor to language]


\subsection{Metalanguage}

The \emph{metalanguage} is the language that the sugars are written
in. There are a number of common possibilities:
\begin{itemize}
\item The metalanguage may be the host language itself.
\item The metalanguage may be the implementation language of the
  compiler (which is frequently the same language).
\item The metalanguage may be a set of pattern-based rules in the general
style of Scheme's \Code{syntax-rules}. In \cref{table:taxonomy-table},
we use ``rules'' as a shorthand for ``a set of pattern-based
desugaring rules''.
\end{itemize}


\subsection{Desugaring Order}\label{sec:taxonomy-order}
% https://dl.acm.org/citation.cfm?id=1440085
% GRAMMARS WITH MACRO-LIKE PRODUCTIONS (Fischer)

There are two major desugaring strategies used in desugaring systems.
They loosely correspond to the call-by-value and call-by-name run-time evaluation strategies, but
differ in some important ways, so we will instead refer
to them by their original names: Outside-in (\Sc{oi}) and
Inside-out (\Sc{io}) desugaring:~\cite{expansion-order}\marginpar{%
You can also ask whether desugaring proceeds left-to-right or
  right-to-left. However, this is a comparatively minor detail, so we
  ignore it.
}
\begin{description}
\item[\Sc{Outside-in}:] \Sc{oi} desugaring is superficially similar to call-by-name
  evaluation, in that desugaring proceeds from the outside in.
  However, there is one crucial difference: in call-by-name evaluation, if a
  function uses (e.g., does case analysis on) one of its
  arguments, it causes that argument to be evaluated. In contrast,
  if an \Sc{oi} sugar does case analysis on one of its
  parameters (which are pieces of syntax), it does not force that
  parameter to be desugared! Rather, the case analysis happens on the
  uninterpreted syntax of that parameter.

  There is an advantage to this: it allows sugars to truly extend the
  syntax of the language because they can treat the syntax of their
  parameters however they want.
  In the most extreme case, it may be impossible
  to even tell where the innermost sugars are, so \Sc{oi} is the only
  possible desugaring order.
\item[\Sc{Inside-out}:] \Sc{io} desugaring is similar to call-by-value evaluation: the
  innermost sugars desugar first. The above paragraph suggested that
  \Sc{io} order may not be possible, but there are a number of common
  settings in which it is: (i) the syntax that sugars can introduce is
  limited enough that you can always tell where nested sugars are;
  (ii) sugars act on the \Sc{ast} rather than on concrete syntax; or
  (iii) sugars cannot deconstruct their parameters, so the desugaring
  order is largely irrelevant anyways. In these settings, \Sc{io}
  order has the advantage of being more analogous to evaluation (which
  developers are quite familiar with). It is
  also sometimes useful for sugars to use the desugared version of
  their parameters: for example, C++ templates can be used to derive
  specialized implementations for particular types, and it is
  convenient to allow that type to be a template expression.
\end{description}


\subsection{Time of Expansion}

We distinguish between three different ``times'' of expansion:
\begin{description}
\item[Run] means that ``sugars'' are actually expanded at run-time.
  This only occurs for metaprogramming systems, which are not true
  desugaring systems.
\item[Compile] means that sugars are always expanded in a separate
  phase before the program runs. (To be more precise, the phases that
  occur in order are (i) desugar, (ii) compile, and (iii) run. We
  describe this as ``compile'' for simplicity and because
  ``compile-time'' is a well-established phrase.)
\item[Variety] Racket macros can run at an arbitrary number of different
  phases, including at compile-time and at run-time.
\end{description}

\subsection{Expressiveness}

We will examine four measures of expressiveness of each desugaring
system:
\begin{description}
\item[Parameters] What kind of parameters can be passed to a sugar? In
  the most general desugaring systems, any syntactic category---be it
  expression, statement, type, field name, class definition,
  etc.---can be passed to a sugar. Some systems are more limited,
  however: for example, C++ templates can only take types or primitive
  values (e.g., numbers) as parameters.
\item[Result] What kind of syntax can a sugar desugar to? Can it be
  any syntactic category, or is it more limited, e.g., to expressions
  only? For example, C++ templates can only desugar into definitions,
  such as function definitions or struct definitions. They cannot
  desugar into (e.g.) expressions.
\item[Deconstruction] Sugars are given syntax as parameters. Can they
  deconstruct this syntax (e.g., by case analysis) or must
  they treat it parametrically (i.e., only compose it)?

  There is a strong interaction between the ability to deconstruct
  parameters and desugaring order (OI vs. IO). With OI order, the
  parameters that are deconstructed are in the surface language, since
  they haven't been desugared yet. Under IO order, however, the
  parameters are in the core language, because they \emph{have} been
  desugared.
\item[Sugar-defining Sugars] Can sugars define sugars? That is, can a
  sugar expand into the definition of another sugar?
\end{description}
Of course, four measures isn't enough to fully capture how expressive
a desugaring system is! However, it should give a rough idea of the
situations in which it is appropriate to use.


\subsection{Safety}\label{sec:taxonomy-safety}

Last---but certainly not least---we will consider four different
\emph{safety properties} of desugaring systems:\marginpar{%
Safety and expressiveness are counterpoints. Safety comes from the
  ability of the compiler to tell whether you're doing something
  wrong, and the less expressive the language, the easier it is to
  tell.
}
\begin{description}
  \item[Syntactic Safety] Can a sugar expand to syntactically invalid
    code? For example, in the C Preprocessor (\cref{sec:taxonomy-cpre}), this
    (textual) macro:
\begin{CorrectlyIndentedCodes}
#define discriminant(a,b,c) ((b) * (b) - (4 * (a) * (c))
\end{CorrectlyIndentedCodes}
    is a completely valid macro that the preprocessor will happily
    expand for you, leading to syntax errors at its use site because
    its parentheses aren't balanced.

    Thus we will call the C Preprocessor \emph{syntactically unsafe}.
    In contrast, a syntactically safe desugaring system would raise an
    error on such a sugar definition, \emph{even if that sugar was
      never used}. This is roughly analogous to type checking: a type checker
    will warn that a function definition contains a type error even
    if that function is never used.

    Lisps (i.e., languages with parenthetical syntax) have an
    interesting relationship to syntactic safety because they generally have two
    ``layers'' of syntax.
    The lower layer is simply s-expressions, and ensures that parentheses
    are well-balanced (and that there are no tokenization errors).
    The higher layer checks that the s-expression makes syntactic sense.
    For example, in Scheme, \Code{(define x 1} is invalid at both layers,
    \Code{(define ((x)) 1)} is valid at the first layer but not at the
    second, and \Code{(define x 1)} is valid at both layers.
    This can be called \emph{bicameral syntax}~\cite[page 13]{plai}, by analogy to legislative
    houses that are split into a lower and upper level.

    As a result, it is possible for a Lisp's macro system to respect
    the lower layer of syntax, but not the higher layer. And in fact
    all of the Lisps we assessed fall into this category. We write
    this in the table as ``partly'' syntax safe.

  \item[Hygiene] Unlike the other safety properties discussed here,
    hygiene~\cite{hygienic-macros} is not about the error behavior of the desugaring
    system.  Instead, it is about how desugaring treats variables. As
    an example, consider this simple \Code{or} sugar (using Racket
    syntax):\marginpar{Why not just write \Code{(if a a b)}? That
      wouldn't work well if \Code{a} had side effects.}
\begin{CorrectlyIndentedCodes}
(define-syntax-rule
  (or a b)
  (let ((temp a)) (if temp temp b)))
\end{CorrectlyIndentedCodes}
    If a desugaring system did nothing special with variables, then
    this code:
\begin{CorrectlyIndentedCodes}
(let ((temp "70 degrees"))
  (or false temp))
\end{CorrectlyIndentedCodes}
    would desugar into this code:
\begin{CorrectlyIndentedCodes}
(let ((temp "70 degrees"))
  (let ((temp false)) (if temp temp temp)))
\end{CorrectlyIndentedCodes}\marginpar{%
  Some of the examples here were inspired by Clinger and Rees~\cite{macros-that-work}.
}
    which would then evaluate to \Code{false}, which is wrong. The
    issues is that the user-written variable called \Code{temp} is
    captured by the sugar-introduced variable called \Code{temp}.
    Thus this naive desugaring is \emph{unhygienic}.
    
    At its core, hygiene is lexical scoping for sugars. You should be
    able to tell where a user-written variable is bound by looking at
    its code (in the example, see that the \Code{temp} in \Code{or
      false temp} should be bound by the surrounding \Code{let}).
    Likewise,
    you should be able to tell where a sugar-introduced variable is
    bound by looking at the sugar definition (and there are analogous
    examples where a sugar-introduced variable gets captured by a
    user-written variable).

    While this account of hygiene is sufficient for this chapter's
    purposes, there is plenty more to say about hygiene. For an
    overview of the various kinds of possible hygiene violations, see
    Adams~\cite{adams-hygiene}. For an alternative take on the hygiene
    property, see \cref{sec:rscope-hygiene-overview} of this thesis.
    
  \item[Scope Safety] Can a sugar \emph{introduce} scope errors?  We
    will say that a desugaring system is \emph{scope safe} if sugars
    cannot introduce an unbound identifier or cause a user-defined
    variable to become unbound.

  \item[Type Safety] Can a sugar introduce type errors? We will say
    that a desugaring system is \emph{type safe} if sugars cannot
    introduce type errors. For example, this MetaOCaml program (the
    \Code{.< ... >.} syntax quotes an expression):
\begin{CorrectlyIndentedCodes}
let sugar() = .<3 + "four">.;;
\end{CorrectlyIndentedCodes}
    does not compile because of the type error present in the
    sugar---even though the sugar is never used.
\end{description}

\section{Applying the Taxonomy to Desugaring Systems}\label{sec:taxonomy-systems}

In this section, we apply the taxonomy to a number of desugaring
systems.\marginpar{Every desugaring system in the table
  was tested except for Early Lisp Macros, McMicMac, Haskell
  Sugars, and our resugaring systems.}
\Cref{table:taxonomy-table} shows the results, and the rest
of this section briefly describes each desugaring system in turn. The
entries of this table come primarily from test cases, which are
available at \url{https://github.com/justinpombrio/thesis}, in the
\Code{sugars} folder.

\begin{SidewaysTable}
  \small
  \begin{tabular}{l|c @{\hspace{1em}} c @{\hspace{1em}} c @{\hspace{1em}} c @{\hspace{1em}} c
      @{\hspace{1em}} c @{\hspace{1em}} c @{\hspace{1em}} c @{\hspace{1em}} c @{\hspace{1em}} c
      @{\hspace{1em}} c @{\hspace{1em}} c @{\hspace{1em}} c @{\hspace{1em}} c}
    & \rot{Representation}
    & \rot{Authorship}
    & \rot{Metalanguage}
    & \rot{Desugaring Order}
    & \rot{Time of Expansion}
%    & \rot{Number of Phases}
    & \rot{Parameters} & \rot{Result} & \rot{Deconstruction} & \rot{Sugar-defining Sugars}
    & \rot{Syntax Safe} & \rot{Hygienic} & \rot{Scope Safe} & \rot{Type Safe}
    \\ \hline
    \textbf{Lisps}
    \\
    Early Lisp Macros
    & abstract
    & user
    & Lisp
    & OI
    & compile
%    & one
    & any & any & yes & yes
    & partly & no & no & NA
    \\
    Scheme Macros
    & concrete
    & user
    & Scheme
    & OI
    & compile
%    & many
    & any & any & yes & yes
    & partly & yes & no & NA
    \\
    Racket Macros
    & concrete
    & user
    & Racket
    & OI
    & variety
%    & many
    & any & any & yes & yes
    & partly & yes & no & no
    \\
    McMicMac Micros
    & concrete$\to$\Sc{ir}
    & language
    & rules
    & OI
    & compile
%    & one
    & any & yes & any & no
    & partly & yes & no & NA
    \\ \hline
    \textbf{Non-Lisps}
    \\
    C Preprocessor
    & token stream
    & user
    & rules
    & IO
    & compile
%    & one
    & any & any & no & no
    & no & no & no & no
    \\
    C++ Templates
    & concrete
    & user
    & rules
    & IO
    & compile
%    & one
    & type* & declaration* & yes & yes
    & yes & NA & NA & no
    \\
    Template Haskell
    & concrete/abstract
    & user
    & Haskell
    & IO
    & compile
%    & many
    & any & any & yes & no
    & yes & no & no & no
    \\
    Haskell Sugars
    & abstract
    & language
    & rules
    & OI
    & compile
%    & one
    & any & any & yes & no
    & yes & no & no & NA
    \\
    Rust Macros
    & concrete
    & user
    & rules
    & OI
    & compile
%    & one
    & any & any & yes & yes
    & no & yes & no & no
    \\
    Julia Macros
    & concrete/abstract
    & user
    & Julia
    & OI
    & compile
%    & many*
    & any & any & yes & yes
    & yes & no & no & NA
    \\
    MetaOCaml
    & concrete
    & user
    & OCaml
    & IO
    & run
%    & many
    & expr & expr & no & yes
    & yes & yes & yes & yes
    \\ \hline
    \textbf{Resugaring}
    \\
    Eval. Resugaring
    & abstract
    & either
    & rules
    & OI
    & compile
%    & one
    & any & any & no & no
    & yes & yes & no & NA
    \\
    Scope Resugaring
    & abstract
    & either
    & rules
    & OI
    & compile
%    & one
    & any & any & yes & no
    & yes & yes & yes & NA
    \\
    Type Resugaring
    & abstract
    & either
    & rules
    & OI
    & compile
%    & one
    & any & any & yes & no
    & yes & yes & yes & yes
  \end{tabular}
  \caption{Taxonomization of Desugaring Systems. (Categories with
    asterisks are described further in that desugaring system's
    subsection. Under Metalanguage, ``rules'' means
    ``pattern-based desugaring rules'', \`a la \Code{syntax-rules}.)}
  \label{table:taxonomy-table}
\end{SidewaysTable}


\subsection{Early Lisp Macros}

Early versions of Lisp~\cite{special-forms-in-lisp,evolution-of-lisp,lisp15,maclisp}
introduced over time a variety of macro-like features, including:
the \Code{eval} operator (which takes an s-expression as an argument
at runtime, and interprets it as code); fexprs (functions whose
arguments are passed to them without first being evaluated);
quasiquotations~\cite{quasiquote}; and macros.
These macros were arbitrary Lisp functions from s-expression to
s-expression that run at compile-time. They were unhygienic; indeed,
even the notion of hygiene had yet to be worked out.

\subsection{Scheme Macros}
\Desc{Version: R5RS, as implemented in Racket v6.10.1}

The Scheme language~\cite{scheme5} was the first to introduce pattern-based
desugaring rules~\cite{macro-by-example}, and hygienic macro expansion~\cite{hygienic-macros}. It set
the stage for desugaring systems to come, including this thesis. The
fact that we have so little to say about Scheme's macros is testament
to how standard its view of macros has become.

\subsection{Racket Macros}
\Desc{Version: Racket v6.10.1}

Racket~\cite{plt-tr1} has an extremely powerful and heavily used macro
system. It is part and parcel of the language: Racket is meant to be a
language for defining languages, and does so with its macro system.
Dozens of languages have been defined this way, including:
\begin{itemize}
\item The Racket language itself, most of which is defined by macros
  (including most of its mechanisms for defining macros).
\item The Typed Racket language, whose type system is defined entirely
  by macros~\cite{typed-racket}.
\item A number of non-programming languages, such as the Scribble
  document templating system~\cite{scribble}.
\end{itemize}
Given the way Racket's macros are used, they are best viewed as
compiler extensions more than simply syntactic sugar.

For an overview of the aspirations of Racket and its macro system, see
the Racket Manifesto~\cite{racket-manifesto}.


\subsection{McMicMac Micros} \label{sec:taxonomy-mcmicmac}

% The author says:
% - macro/micro split important
% - internal representation is enriched s-exprs (as in Racket)
% - Use case: want to change how argument lists work
%             but there is no such thing as an argument list in Schem
%             thus have to change define, let, etc. etc.
%             with micros, easy

Krishnamurthi et al. describe a desugaring system called
McMicMac~\cite{sk:mcmicmac} that is based on a combination of macros
and \emph{micros}, and built on top of Scheme. While macros perform an
\Sc{ast}-to-\Sc{ast} transformation, \emph{micros} transform the \Sc{ast}
to an \Sc{ir} (an ``intermediate representation'' used by the compiler).
Relevantly, the \Sc{ir} is treated as data and cannot contain macros
or micros, and is thus not recursively desugared.

Micros extend macros in a couple of ways:
\begin{itemize}
  \item Micros can take as arguments and produce as results values
    that aren't just syntax. For example, a set of micros can keep
    track of the lexical environment, and use it to compute the set of
    free variables of a term.
  \item Micros can be grouped into \emph{vocabularies}, with each
    vocabulary representing a different kind of transformation, and
    these vocabularies can be composed.
\end{itemize}
Overall, McMicMac promotes micros as a useful generalization of macros.


% Sugars that I was able to find in the c language, as defined by the spec:
%   E1[E2] === (*((E1)+(E2)))
%   ++E === (E+=1)
%   !E === (0==E)
% There are not sugar:
%   (&E)->MOS === E.MOS
%   &*E === E
\subsection{C Preprocessor} \label{sec:taxonomy-cpre}
\Desc{Version: gcc v6.3.0}

% https://gcc.gnu.org/onlinedocs/cpp/
% Not Turing complete: https://gcc.gnu.org/onlinedocs/cpp/Self-Referential-Macros.html
% desugaring order: https://gcc.gnu.org/onlinedocs/cpp/Macro-Arguments.html
%   also section 6.10.3.1: http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1124.pdf
The C Preprocessor (hereafter \Sc{cpp})~\cite{cpp} is a \emph{text
  preprocessor}: a source-to-source transformation that operates at
the level of text. (More precisely, it operates on a token stream, in
which the tokens are approximately those of the C language). It is
usually run before compilation for C or C++ programs, but it is not
very language specific, and can be used for other purposes as well.
Unlike the rest of the desugaring systems described in this chapter,
\Sc{cpp} is not Turing complete.
It avoids Turing completeness by a simple mechanism: if a macro
invokes itself (directly or indirectly), the recursive invocation
will not be expanded.

%https://stackoverflow.com/questions/14041453/why-are-preprocessor-macros-evil-and-what-are-the-alternatives
A number of issues arise from the fact that \Sc{cpp} operates on tokens, and
is thus unaware of the higher-level syntax of C~\cite{c-standard}.
As an example, consider this innocent looking
\Sc{cpp} desugaring rule that defines an alias for subtraction:
\begin{Codes}
  #define SUB(a, b) a - b
\end{Codes}
This rule is completely broken. Suppose it is used as follows:
\begin{Codes}
  SUB(0, 2 - 1))
\end{Codes}
This will expand to \Code{0 - 2 - 1} and evaluate to \Code{-3}.
We can revise the rule to fix this:
\begin{Codes}
  #define SUB(a, b) (a) - (b)
\end{Codes}
This will fix the last example, but it is still broken. Consider:
\begin{Codes}
  SUB(5, 3) * 2
\end{Codes}
This will expand to \Code{5 - 3 * 2} and evaluate to \Code{-1}.
The rule can be fully fixed by another set of parentheses:
\begin{Codes}
  #define SUB(a, b) ((a) - (b))
\end{Codes}
In general, both the inside boundary of a rule (the parameters \Code{a}
and \Code{b}), and the outside boundary (the whole \Sc{rhs}) need
to be protected to ensure that the expansion is parsed correctly. If
the sugar is used in expression position, as in the \Code{SUB}
example, this can be done with parentheses. In other positions,
different tricks must be used: e.g., a rule meant to be used in
statement position can be wrapped in \Code{do \{...\} while(0)}.
This is a poor state of affairs: software developers should not need
to learn and remember to use tricks like this simply to write working
macros.

There are other issues that arise with text-based transformations as
well, such as variable capture. Furthermore, all of these issues are
inherent to text-based transformations, and cannot be
fixed from within the paradigm. \emph{Overall, code transformations
  should never operate at the level of text (or token streams).}

\subsection{C++ Templates} \label{sec:taxonomy-cpp}
\Desc{Version: g++ v4.8.4}

% http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4659.pdf
C++ templates~\cite{cpp-standard} are not general-purpose sugars,
because they cannot take code as a parameter. Thus you cannot, for
example, express a sugar that takes an expression \Code{e} and expands
it to \Code{e + 1}.

Instead, C++ templates are used
primarily to instantiate polymorphic code by replacing type parameters
with concrete types.  For example, take the following template declarations
from~\cite[page 344]{cpp-standard}:
\begin{Codes}
template<class T>
constexpr T pi = T(3.1415926535897932385L);

template<class T>
T circular_area(T r) \{
  return pi<T> * r * r;
\}
\end{Codes}
The first template declares a constant \Code{pi}, which can be
instantiated with different (presumably numeric) types \Code{T}.
The second template declares a function \Code{circular\_area}, which
can also be parameterized over different types \Code{T}, and uses
\Code{T} both for its radius argument and for its \Code{pi} constant.
We'll use this function template as a running example.

Besides function definitions, several other kinds of declarations can
be templated, including methods, classes, structs, and type aliases.
The behavior of each is similar. A template may be invoked by passing
parameters in angle brackets. An invoked template acts like the
kind of thing the template declared, and can be used in the same
positions. Thus, e.g., a \Code{struct} template should be invoked in type
position; and our running function template example should be invoked
in expression position to make a function, which can then be called:
\begin{Codes}
  float area = circular_area<float>(1);
\end{Codes}
When a template is invoked like this, a copy of the template
definition is made, with the template parameters replaced with the
concrete parameters.\marginpar{
  If a template is invoked multiple times with the same parameters,
  only one copy of the code will be made, however.
}
In our example, this produces the code:
\begin{Codes}
float circular_area(float r) \{
  return pi<float> * r * r;
\}
\end{Codes}

So far we have only described type parameters, but templates can also
take other kinds of parameters, including primitive values (such as
numbers) and other templates. The ability to manipulate numbers and
invoke other templates at compile time make C++ templates powerful
and, unsurprisingly, Turing complete. However, templates \emph{cannot}
be parameterized over code, and thus are not general-purpose sugars.
For example, most of the examples in this thesis cannot be written as
C++ templates.

Template expansion uses IO desugaring order. This is important because
it is possible
to define both a generic template that applies most of the time, and
a specialized template that applies if a parameter has a particular
value. For example, this could be used to make a \Code{HashMap} use a different
implementation if its keys are \Code{int}s. Thus it is important that
a template see the concrete type (e.g. \Code{int}) that is passed to
it, even if this type is the result of another template expansion.

\subsection{Template Haskell} \label{sec:taxonomy-haskell}
\Desc{Version: GHC v7.6.3}

%https://hackage.haskell.org/package/template-haskell-2.10.0.0/docs/Language-Haskell-TH-Syntax.html#t:Lit
%https://stackoverflow.com/questions/10857030/whats-so-bad-about-template-haskell
Haskell allows user-defined sugars by way of the Template Haskell
system~\cite{haskell-templates}. It allows terms to be written either in concrete surface
syntax:
\begin{Codes}
  [| 1 + 2 |]
\end{Codes}
or in abstract surface syntax:
\begin{Codes}
  return \$ AppE (AppE (VarE '(+))
                      (LitE (IntegerL 1)))
                (LitE (IntegerL 2))
\end{Codes}

It maintains hygiene by requiring terms to be wrapped in a Monad
(called \Code{Q}) that ensures that introduced variables are given
fresh names (unless explicitly marked otherwise). However, this can
easily be broken via quotation brackets (\Code{[| ... |]}), so we
count Template Haskell as unhygienic.


\subsection{Haskell Sugars}

Besides its template system, Haskell also has some sugars built in to
the language. For example, the Haskell specification states that list
comprehensions~\cite[section 3.11]{haskell-language} are
given by the following transformation:
\begin{verbatim}
  [e | True]         = [e]
  [e | q]            = [e | q, True]
  [e | b, Q]         = if b then [e | Q] else []
  [e | p <- l, Q]    = let ok p = [e | Q]
                           ok _ = []
                       in concatMap ok l
  [e | let decls, Q] = let decls in [e | Q]
\end{verbatim}
We will use this sugar as a case study for both resugaring scope rules
(\cref{sec:list-rscope-example}) and resugaring type rules
(\cref{sec:rtype-eval-case}).

\paragraph{Note:}
Haskell actually has a \emph{third} kind of sugar: its pragma system
supports rewrite rules~\cite{haskell-pragmas}.

\subsection{Rust Macros}
\Desc{Version: 1.24.0-nightly}

%https://doc.rust-lang.org/1.2.0/book/macros.html
Rust has a hygienic macro system with pattern-based rules similar to
Scheme's \Code{syntax-rules}. Rust also has a second
``procedural'' macro system. This secondary macro system allows
macros to be written as arbitrary Rust functions. However, it can only
be used in very specific circumstances---at the time of this writing,
only to add custom \Code{derive} traits---so we do not discuss it
further.

\subsection{Julia Macros}
\Desc{Version: 0.4.5}

Julia macros are written as Julia functions, and can construct and
deconstruct arbitrary syntax. They are mostly unhygienic. (The user
guide discusses hygiene, but in testing the macro system appears to be unhygienic
outside of the specific situations described.) Beyond this, Julia also
allows arbitrary run-time metaprogramming: constructing,
deconstructing, and evaluating code at run-time.
\Cref{table:taxonomy-table} describes only Julia's macro system.

\subsection{MetaOCaml} \label{sec:taxonomy-metaocaml}

MetaOCaml is a \emph{multi-stage programming} extension to OCaml. This
means that it provides three new constructs to the language:
\begin{description}
\item[Brakcets] (written \Code{.< $\cdots$ >.}) Quote an expression,
  producing a syntax value at run-time.
\item[Escape] (written \Code{.$\sim$}) Splice values into a quotation.
\item[Run] (written \Code{.!}, or \Code{run}) Given a syntax value at
  run-time, evaluate it.
\end{description}
Thus this code:
\begin{Codes}
open Runcode;;
open Printf;;
let x = .<printf("k")>. in !. .<(.~x; .~x)>.;;
\end{Codes}
prints \Code{kk}. This method of programming is called
\emph{multi-stage} because these quotations can be arbitrarily
nested. An expression under $n$ quotations is said to run in stage
$n$.

The \emph{upside} to multi-stage programming is that it can provide
very strong safety guarantees. MetaOCaml guarantees that staged
functions (i.e., functions that produce quoted code) cannot produce
ill-formed, ill-scoped, or ill-typed code. This is checked at
compile-time, before the staged function is even invoked. This is
vastly safer than the other desugaring systems we surveyed.

The \emph{downside} to multi-stage programming is that it is not a
full-fledged desugaring system. It cannot introduce new syntax, it
cannot deconstruct syntax, and its ``desugaring'' happens explicitly
at run-time via calls to \Code{run}. For all of these reasons,
multi-staged programming is best viewed as a way of more efficiently
organizing computation rather than as a means of extending a language.

\subsection{Resugaring Systems}

\Cref{table:taxonomy-table} lists our three resugaring systems. This
is referring to the \emph{kinds of desugaring systems} that these
resugaring approaches support. There are two interesting aspects worth
discussing.

First, while the resugaring systems appear to do well on the
expressiveness front, there is a limitation hidden in the metalanguage
being ``rules''.  While many of the other desugaring systems provide
an ``escape hatch'' out of their ``rules'' allowing arbitrary code to
run during the desugaring process, our resugaring work strictly
requires pattern-based rules.

Second, the safety guarantees are provided by a mix of the
\emph{desugaring} and \emph{resugaring} systems. Each of the resugaring
systems is marked as ``syntax safe'' and ``hygienic'', because those
are assumptions it makes about the desugaring system it is built on
top of. Scope resugaring is additionally marked as ``scope safe'',
because scope resugaring would \emph{reject} any sugar that was not
scope safe. Likewise, type resugaring would reject any sugar that was
not type safe (and as a result any sugar that was not scope safe).
